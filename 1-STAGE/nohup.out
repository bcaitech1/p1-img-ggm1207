wandb: Starting wandb agent üïµÔ∏è
2021-03-29 21:21:13,481 - wandb.wandb_agent - INFO - Running runs: []
2021-03-29 21:21:13,783 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:21:13,783 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 120
	epochs: 20
	lr: 0.0004494310169612834
	optimizer: sgd
	seed: 4692
	test: False
	train_key: gender
2021-03-29 21:21:13,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=120 --epochs=20 --lr=0.0004494310169612834 --optimizer=sgd --seed=4692 --test=False --train_key=gender
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run youthful-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/1i5i8jkj
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_212115-1i5i8jkj
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:21:18,819 - wandb.wandb_agent - INFO - Running runs: ['1i5i8jkj']
Epoch: 01 | Time: 1m 16s
	Train Loss: 0.686
	Validation Loss: 0.682
	Validation Accuracy: 0.615
Epoch: 02 | Time: 1m 15s
	Train Loss: 0.680
	Validation Loss: 0.678
	Validation Accuracy: 0.615
Epoch: 03 | Time: 1m 15s
	Train Loss: 0.676
	Validation Loss: 0.675
	Validation Accuracy: 0.615
Epoch: 04 | Time: 1m 15s
	Train Loss: 0.673
	Validation Loss: 0.672
	Validation Accuracy: 0.615
Epoch: 05 | Time: 1m 15s
	Train Loss: 0.671
	Validation Loss: 0.670
	Validation Accuracy: 0.615
Epoch: 06 | Time: 1m 15s
	Train Loss: 0.670
	Validation Loss: 0.669
	Validation Accuracy: 0.615
Epoch: 07 | Time: 1m 15s
	Train Loss: 0.669
	Validation Loss: 0.668
	Validation Accuracy: 0.615
Epoch: 08 | Time: 1m 15s
	Train Loss: 0.668
	Validation Loss: 0.667
	Validation Accuracy: 0.615
Epoch: 09 | Time: 1m 15s
	Train Loss: 0.667
	Validation Loss: 0.667
	Validation Accuracy: 0.615
2021-03-29 21:33:40,040 - wandb.wandb_agent - INFO - Cleaning up finished run: 1i5i8jkj
2021-03-29 21:33:40,330 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:33:40,330 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 56
	epochs: 20
	lr: 0.0006090118622910788
	optimizer: adam
	seed: 3212
	test: False
	train_key: mask
2021-03-29 21:33:40,332 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=56 --epochs=20 --lr=0.0006090118622910788 --optimizer=adam --seed=3212 --test=False --train_key=mask
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run gallant-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/rsgg9dtd
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213342-rsgg9dtd
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:33:45,366 - wandb.wandb_agent - INFO - Running runs: ['rsgg9dtd']
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:33:55,804 - wandb.wandb_agent - INFO - Cleaning up finished run: rsgg9dtd
2021-03-29 21:33:56,078 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:33:56,078 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 81
	epochs: 20
	lr: 0.0008972578503143284
	optimizer: adam
	seed: 7374
	test: False
	train_key: mask
2021-03-29 21:33:56,080 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=81 --epochs=20 --lr=0.0008972578503143284 --optimizer=adam --seed=7374 --test=False --train_key=mask
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run rare-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/en7m2hgl
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213358-en7m2hgl
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:34:01,113 - wandb.wandb_agent - INFO - Running runs: ['en7m2hgl']
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
Traceback (most recent call last):
  File "train.py", line 166, in <module>
    main(args)
  File "train.py", line 156, in main
    run(args, model, optimizer, loss_fn, train_dataloader, test_dataloader)
  File "train.py", line 100, in run
    train_loss = train(args, model, optimizer, loss_fn, train_dataloader)
  File "train.py", line 49, in train
    loss.backward()
  File "/opt/conda/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: The wandb backend process has shutdown
wandb: Waiting for W&B process to finish, PID 27278
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:34:11,537 - wandb.wandb_agent - INFO - Cleaning up finished run: en7m2hgl
2021-03-29 21:34:11,832 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:34:11,832 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 33
	epochs: 20
	lr: 0.00032282725270586885
	optimizer: adam
	seed: 6113
	test: False
	train_key: gender
2021-03-29 21:34:11,834 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=33 --epochs=20 --lr=0.00032282725270586885 --optimizer=adam --seed=6113 --test=False --train_key=gender
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run peachy-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/1qt4075w
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213413-1qt4075w
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:34:16,869 - wandb.wandb_agent - INFO - Running runs: ['1qt4075w']
2021-03-29 21:34:22,081 - wandb.wandb_agent - INFO - Cleaning up finished run: 1qt4075w
2021-03-29 21:34:22,395 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:34:22,395 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 76
	epochs: 20
	lr: 0.000772088249186041
	optimizer: sgd
	seed: 4462
	test: False
	train_key: age
2021-03-29 21:34:22,397 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=76 --epochs=20 --lr=0.000772088249186041 --optimizer=sgd --seed=4462 --test=False --train_key=age
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run distinctive-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/byjrj9g0
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213424-byjrj9g0
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:34:27,418 - wandb.wandb_agent - INFO - Running runs: ['byjrj9g0']
2021-03-29 21:34:32,635 - wandb.wandb_agent - INFO - Cleaning up finished run: byjrj9g0
2021-03-29 21:34:32,924 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:34:32,924 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 101
	epochs: 20
	lr: 0.0003761652508646096
	optimizer: sgd
	seed: 9725
	test: False
	train_key: gender
2021-03-29 21:34:32,925 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=101 --epochs=20 --lr=0.0003761652508646096 --optimizer=sgd --seed=9725 --test=False --train_key=gender
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run northern-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/ljpd233o
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213434-ljpd233o
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:34:37,960 - wandb.wandb_agent - INFO - Running runs: ['ljpd233o']
2021-03-29 21:34:37,962 - wandb.wandb_agent - INFO - Cleaning up finished run: ljpd233o
2021-03-29 21:34:38,240 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:34:38,240 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 127
	epochs: 20
	lr: 0.0003588573008772664
	optimizer: sgd
	seed: 6960
	test: False
	train_key: age
2021-03-29 21:34:38,242 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=127 --epochs=20 --lr=0.0003588573008772664 --optimizer=sgd --seed=6960 --test=False --train_key=age
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run exalted-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/u359113w
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213440-u359113w
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:34:43,276 - wandb.wandb_agent - INFO - Running runs: ['u359113w']
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:34:48,492 - wandb.wandb_agent - INFO - Cleaning up finished run: u359113w
2021-03-29 21:34:48,779 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:34:48,779 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 80
	epochs: 20
	lr: 0.00039951448447076386
	optimizer: sgd
	seed: 8991
	test: False
	train_key: mask
2021-03-29 21:34:48,781 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=80 --epochs=20 --lr=0.00039951448447076386 --optimizer=sgd --seed=8991 --test=False --train_key=mask
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run genial-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/ti1k1zfr
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213450-ti1k1zfr
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:34:53,815 - wandb.wandb_agent - INFO - Running runs: ['ti1k1zfr']
Traceback (most recent call last):
  File "train.py", line 166, in <module>
    main(args)
  File "train.py", line 156, in main
    run(args, model, optimizer, loss_fn, train_dataloader, test_dataloader)
  File "train.py", line 119, in run
    "epoch": epoch,
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 1054, in log
    self.history._row_add(data)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_history.py", line 44, in _row_add
    self._flush()
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_history.py", line 59, in _flush
    self._callback(row=self._data, step=self._step)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 805, in _history_callback
    row, step, publish_step=not_using_tensorboard
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 222, in publish_history
    self._publish_history(history)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 206, in _publish_history
    self._publish(rec)
  File "/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 518, in _publish
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
wandb: ERROR Problem finishing run
/opt/conda/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
2021-03-29 21:36:22,479 - wandb.wandb_agent - INFO - Cleaning up finished run: ti1k1zfr
2021-03-29 21:36:22,753 - wandb.wandb_agent - INFO - Agent received command: run
2021-03-29 21:36:22,753 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 117
	epochs: 20
	lr: 0.000718490520249413
	optimizer: sgd
	seed: 6254
	test: False
	train_key: mask
2021-03-29 21:36:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --batch_size=117 --epochs=20 --lr=0.000718490520249413 --optimizer=sgd --seed=6254 --test=False --train_key=mask
wandb: Currently logged in as: ggm1207 (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep
PyTorch version:[1.6.0].
This code use [cuda:0].
wandb: Tracking run with wandb version 0.10.23
wandb: Syncing run fanciful-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ggm1207/P-Stage-1-STAGE
wandb: üßπ View sweep at https://wandb.ai/ggm1207/P-Stage-1-STAGE/sweeps/rx97gjjn
wandb: üöÄ View run at https://wandb.ai/ggm1207/P-Stage-1-STAGE/runs/fkztjpp3
wandb: Run data is saved locally in /opt/ml/P-Stage/1-STAGE/wandb/run-20210329_213624-fkztjpp3
wandb: Run `wandb offline` to turn off syncing.
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'epochs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'train_key' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'test' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer' was locked by 'sweep' (ignored update).
2021-03-29 21:36:27,791 - wandb.wandb_agent - INFO - Running runs: ['fkztjpp3']
